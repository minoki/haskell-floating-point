
//
// {{TYPE}}
//

static inline {{TYPE}} rounded_add_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a, {{TYPE}} b)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} c = a + b;
    restore_fp_reg(oldreg);
    return c;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_add_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a, {{TYPE}} b)
{ return rounded_add_impl_{{NAME}}({{MODE_ARG}}, a, b); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_sub_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a, {{TYPE}} b)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} c = a - b;
    restore_fp_reg(oldreg);
    return c;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_sub_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a, {{TYPE}} b)
{ return rounded_sub_impl_{{NAME}}({{MODE_ARG}}, a, b); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_mul_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a, {{TYPE}} b)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} c = a * b;
    restore_fp_reg(oldreg);
    return c;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_mul_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a, {{TYPE}} b)
{ return rounded_mul_impl_{{NAME}}({{MODE_ARG}}, a, b); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_div_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a, {{TYPE}} b)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} c = a / b;
    restore_fp_reg(oldreg);
    return c;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_div_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a, {{TYPE}} b)
{ return rounded_div_impl_{{NAME}}({{MODE_ARG}}, a, b); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_sqrt_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
#if defined(__GNUC__) && defined(USE_SSE2)
    // mingw-w64's {{sqrt}} may use x87 instead of SSE2
    {{TYPE}} c;
    __asm__ volatile("{{sqrt_sse}} %1, %0" : "=x"(c) : "x"(a));
#else
    volatile {{TYPE}} c = {{sqrt}}(a);
#endif
    restore_fp_reg(oldreg);
    return c;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_sqrt_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a)
{ return rounded_sqrt_impl_{{NAME}}({{MODE_ARG}}, a); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_fma_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a, {{TYPE}} b, {{TYPE}} c)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} result = {{fma}}(a, b, c);
    restore_fp_reg(oldreg);
    return result;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_fma_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a, {{TYPE}} b, {{TYPE}} c)
{ return rounded_fma_impl_{{NAME}}({{MODE_ARG}}, a, b, c); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_fma_if_fast_impl_{{NAME}}(native_rounding_mode mode, {{TYPE}} a, {{TYPE}} b, {{TYPE}} c)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
#ifdef {{FP_FAST_FMA}}
    volatile {{TYPE}} result = {{fma}}(a, b, c);
#else
    volatile {{TYPE}} result = a * b + c;
#endif
    restore_fp_reg(oldreg);
    return result;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_fma_if_fast_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}{{TYPE}} a, {{TYPE}} b, {{TYPE}} c)
{ return rounded_fma_if_fast_impl_{{NAME}}({{MODE_ARG}}, a, b, c); }
{{/each_rounding_mode}}

//
// Conversion
//

static inline {{TYPE}} rounded_int64_to_{{NAME}}_impl(native_rounding_mode mode, int64_t x)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} result = ({{TYPE}})x;
    restore_fp_reg(oldreg);
    return result;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_int64_to_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}int64_t x)
{ return rounded_int64_to_{{NAME}}_impl({{MODE_ARG}}, x); }
{{/each_rounding_mode}}

static inline {{TYPE}} rounded_word64_to_{{NAME}}_impl(native_rounding_mode mode, uint64_t x)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, mode);
    volatile {{TYPE}} result = ({{TYPE}})x;
    restore_fp_reg(oldreg);
    return result;
}
{{#each_rounding_mode}}
extern {{TYPE}} rounded_hw_word64_to_{{NAME}}{{MODE_SUFFIX}}({{MODE_PARAM}}uint64_t x)
{ return rounded_word64_to_{{NAME}}_impl({{MODE_ARG}}, x); }
{{/each_rounding_mode}}

//
// Interval arithmetic
//

static inline {{TYPE}} fast_fmax_{{NAME}}({{TYPE}} x, {{TYPE}} y)
{
    // should compile to MAX[SP][SD] instruction on x86
    return x > y ? x : y;
}
static inline {{TYPE}} fast_fmax4_{{NAME}}({{TYPE}} x, {{TYPE}} y, {{TYPE}} z, {{TYPE}} w)
{
    return fast_fmax_{{NAME}}(fast_fmax_{{NAME}}(x, y), fast_fmax_{{NAME}}(z, w));
}
static inline {{TYPE}} fast_fmin_{{NAME}}({{TYPE}} x, {{TYPE}} y)
{
    // should compile to MIN[SP][SD] instruction on x86
    return x < y ? x : y;
}
static inline {{TYPE}} fast_fmin4_{{NAME}}({{TYPE}} x, {{TYPE}} y, {{TYPE}} z, {{TYPE}} w)
{
    return fast_fmin_{{NAME}}(fast_fmin_{{NAME}}(x, y), fast_fmin_{{NAME}}(z, w));
}

extern {{TYPE}} rounded_hw_interval_mul_{{NAME}}_up({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_UPWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 * lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 * hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 * lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 * hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    {{TYPE}} hi = fast_fmax4_{{NAME}}(x, y, z, w);
    restore_fp_reg(oldreg);
    return hi;
}

extern {{TYPE}} rounded_hw_interval_mul_{{NAME}}_down({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_DOWNWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 * lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 * hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 * lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 * hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    {{TYPE}} lo = fast_fmin4_{{NAME}}(x, y, z, w);
    restore_fp_reg(oldreg);
    return lo;
}

extern {{TYPE}} rounded_hw_interval_mul_add_{{NAME}}_up({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2, {{TYPE}} hi3)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_UPWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 * lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 * hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 * lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 * hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    volatile {{TYPE}} hi = fast_fmax4_{{NAME}}(x, y, z, w) + hi3;
    restore_fp_reg(oldreg);
    return hi;
}

extern {{TYPE}} rounded_hw_interval_mul_add_{{NAME}}_down({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2, {{TYPE}} lo3)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_DOWNWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 * lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 * hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 * lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 * hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 * inf -> 0 */
    volatile {{TYPE}} lo = fast_fmin4_{{NAME}}(x, y, z, w) + lo3;
    restore_fp_reg(oldreg);
    return lo;
}

extern {{TYPE}} rounded_hw_interval_div_{{NAME}}_up({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_UPWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 / lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 / hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 / lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 / hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    {{TYPE}} hi = fast_fmax4_{{NAME}}(x, y, z, w);
    restore_fp_reg(oldreg);
    return hi;
}

extern {{TYPE}} rounded_hw_interval_div_{{NAME}}_down({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_DOWNWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 / lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 / hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 / lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 / hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    {{TYPE}} lo = fast_fmin4_{{NAME}}(x, y, z, w);
    restore_fp_reg(oldreg);
    return lo;
}

extern {{TYPE}} rounded_hw_interval_div_add_{{NAME}}_up({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2, {{TYPE}} hi3)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_UPWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 / lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 / hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 / lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 / hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    volatile {{TYPE}} hi = fast_fmax4_{{NAME}}(x, y, z, w) + hi3;
    restore_fp_reg(oldreg);
    return hi;
}

extern {{TYPE}} rounded_hw_interval_div_add_{{NAME}}_down({{TYPE}} lo1, {{TYPE}} hi1, {{TYPE}} lo2, {{TYPE}} hi2, {{TYPE}} lo3)
{
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, ROUND_DOWNWARD);
    {{TYPE}} x = (volatile {{TYPE}})(lo1 / lo2);
    {{TYPE}} y = (volatile {{TYPE}})(lo1 / hi2);
    {{TYPE}} z = (volatile {{TYPE}})(hi1 / lo2);
    {{TYPE}} w = (volatile {{TYPE}})(hi1 / hi2);
    if (isnan(x)) x = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(y)) y = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(z)) z = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    if (isnan(w)) w = 0.0{{LIT_SUFFIX}}; /* 0 / 0, +-inf / +-inf -> 0 */
    volatile {{TYPE}} lo = fast_fmin4_{{NAME}}(x, y, z, w) + lo3;
    restore_fp_reg(oldreg);
    return lo;
}

//
// Vector Operations
//

extern {{TYPE}} rounded_hw_vector_sum_{{NAME}}(HsInt mode, HsInt length, HsInt offset, const {{TYPE}} *a)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
    volatile {{TYPE}} s = 0.0{{LIT_SUFFIX}};
    for (HsInt i = 0; i < length; ++i) {
        s += a[offset + i];
    }
    restore_fp_reg(oldreg);
    return s;
}

extern void rounded_hw_vector_add_{{NAME}}(HsInt mode, HsInt length, HsInt offsetR, {{TYPE}} * restrict result, HsInt offsetA, const {{TYPE}} * restrict a, HsInt offsetB, const {{TYPE}} * restrict b)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
    for (HsInt i = 0; i < length; ++i) {
        result[offsetR + i] = a[offsetA + i] + b[offsetB + i];
    }
    restore_fp_reg(oldreg);
}

extern void rounded_hw_vector_sub_{{NAME}}(HsInt mode, HsInt length, HsInt offsetR, {{TYPE}} * restrict result, HsInt offsetA, const {{TYPE}} * restrict a, HsInt offsetB, const {{TYPE}} * restrict b)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
    for (HsInt i = 0; i < length; ++i) {
        result[offsetR + i] = a[offsetA + i] - b[offsetB + i];
    }
    restore_fp_reg(oldreg);
}

extern void rounded_hw_vector_mul_{{NAME}}(HsInt mode, HsInt length, HsInt offsetR, {{TYPE}} * restrict result, HsInt offsetA, const {{TYPE}} * restrict a, HsInt offsetB, const {{TYPE}} * restrict b)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
    for (HsInt i = 0; i < length; ++i) {
        result[offsetR + i] = a[offsetA + i] * b[offsetB + i];
    }
    restore_fp_reg(oldreg);
}

extern void rounded_hw_vector_fma_{{NAME}}(HsInt mode, HsInt length, HsInt offsetR, {{TYPE}} * restrict result, HsInt offsetA, const {{TYPE}} * restrict a, HsInt offsetB, const {{TYPE}} * restrict b, HsInt offsetC, const {{TYPE}} * restrict c)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
    for (HsInt i = 0; i < length; ++i) {
        result[offsetR + i] = {{fma}}(a[offsetA + i], b[offsetB + i], c[offsetC + i]);
    }
    restore_fp_reg(oldreg);
}

extern void rounded_hw_vector_div_{{NAME}}(HsInt mode, HsInt length, HsInt offsetR, {{TYPE}} * restrict result, HsInt offsetA, const {{TYPE}} * restrict a, HsInt offsetB, const {{TYPE}} * restrict b)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
    for (HsInt i = 0; i < length; ++i) {
        result[offsetR + i] = a[offsetA + i] / b[offsetB + i];
    }
    restore_fp_reg(oldreg);
}

extern void rounded_hw_vector_sqrt_{{NAME}}(HsInt mode, HsInt length, HsInt offsetR, {{TYPE}} * restrict result, HsInt offsetA, const {{TYPE}} * restrict a)
{
    native_rounding_mode nmode = hs_rounding_mode_to_native(mode);
    fp_reg oldreg = get_fp_reg();
    set_rounding(oldreg, nmode);
#if defined(__GNUC__) && defined(USE_SSE2)
    // mingw-w64's {{sqrt}} may use x87 instead of SSE2
    HsInt i = 0;
    for (; i + {{ELEM_PER_VECTOR}} <= length; i += {{ELEM_PER_VECTOR}}) {
        {{VECTOR}} aa = {{_mm_loadu_px}}(&a[offsetA + i]);
        {{VECTOR}} bb = {{_mm_sqrt_px}}(aa);
        {{_mm_storeu_px}}(&result[offsetR + i], bb);
    }
    for (; i < length; ++i) {
        {{TYPE}} aa = a[offsetA + i];
        {{TYPE}} bb;
        __asm__ volatile("{{sqrt_sse}} %1, %0" : "=x"(bb) : "x"(aa));
        result[offsetR + i] = bb;
    }
#else
    for (HsInt i = 0; i < length; ++i) {
        result[offsetR + i] = {{sqrt}}(a[offsetA + i]);
    }
#endif
    restore_fp_reg(oldreg);
}
